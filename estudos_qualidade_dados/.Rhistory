# Carregando o dataset Iris
data(iris)
# 1.Teste de hipótese para o comprimento da sépala entre setosa e versicolor
setosa_sep_len <- iris$Sepal.Length[iris$Species == 'setosa']
versicolor_sep_len <- iris$Sepal.Length[iris$Species == 'versicolor']
# Realizando um teste t para amostras independentes
t.test(setosa_sep_len, versicolor_sep_len)
# 2. Teste de hipótese para a largura da pétala entre versicolor e virginica
versicolor_pet_width <- iris$Petal.Width[iris$Species == 'versicolor']
virginica_pet_width <- iris$Petal Width[iris$Species == 'virginica']
# Teste t para amostras independentes
t. test(versicolor_pet_width, virginica_pet_width)
#3. Teste de hipótese para o comprimento da sépala da espécie virginica é igual a 6.5 cm
virginica_sep_len <- iris$Sepal.Length[iris$Species == 'virginica']
# Teste t de uma amostra
t.test(virginica_sep_len, mu = 6.5)
installed.packages()
install.packages("dplyr") #Manipulação de dados
install.packages("ggplot2") #Visualização de dados
install.packages("janitor") #Limpeza e resumo dos dados
install.packages("lubridate") #Manipulação de datas
install.packages("naniar") #Visualização de dados faltantes
install.packages("stringr") #Manipulação de textos
install.packages("tidyr") #Transformação de dados
library("dplyr")
library("ggplot2")
library("janitor")
library("lubridate")
library("naniar")
library("stringr")
library("tidyr")
library("naniar")
library("stringr")
# Carregando o dataset 'iris' e criando dados ausentes para demonstração
data("iris")
set.seed(1234) # Para reprodutibilidade
# Introduzindo NA's aleatoriamente em algumas observações da coluna Species
iris$Species[sample(51:150, 25)] <- NA
# Análise de balanceamento de classes com 'tabyl' do 'janitor'
iris_tabyl <- iris |>
janitor::tabyl(Species)
# Exibindo análise
iris_tabyl
# Carregando o dataset 'airquality'
data("airquality")
# Calculando as estatísticas descritivas e percentual de dados faltantes
stats <- airquality |>
dplyr::select(-c("Month", "Day")) |> # Retiradas variáveis que,
# apesar de numéricas, sua análise deve ser feita como categoria.
dplyr::summarise(
dplyr::across(
dplyr::where(is.numeric),
list(
mean = ~mean(., na.rm = TRUE),
median = ~median(., na.rm = TRUE),
sd = ~sd(., na.rm = TRUE),
min = ~min(., na.rm = TRUE),
max = ~max(., na.rm = TRUE),
na_percentage = ~sum(is.na(.)) / n() * 100
),
.names = "{.col}-{.fn}"  # Usando hífen como separador
)
) |>
tidyr::pivot_longer(
cols = everything(),
names_to = c("Variable", ".value"),
names_sep = "-"  # Alinhando o separador com o usado acima
)
# Exibindo as estatísticas descritivas
stats
# Calculando as estatísticas descritivas e percentual de dados faltantes
stats <- airquality |>
dplyr::select(-c("Month", "Day")) |> # Retiradas variáveis que,
# apesar de numéricas, sua análise deve ser feita como categoria.
dplyr::summarise(
dplyr::across( #Identifica uma sequencia de colunas
dplyr::where(is.numeric), #Quais sao as colunas utilizadas no across
list(
mean = ~mean(., na.rm = TRUE),
median = ~median(., na.rm = TRUE),
sd = ~sd(., na.rm = TRUE),
min = ~min(., na.rm = TRUE),
max = ~max(., na.rm = TRUE),
na_percentage = ~sum(is.na(.)) / n() * 100
),
.names = "{.col}-{.fn}"  # Usando hífen como separador
)
)
# Exibindo as estatísticas descritivas
stats
# Calculando as estatísticas descritivas e percentual de dados faltantes
stats <- airquality |>
dplyr::select(-c("Month", "Day")) |> # Retiradas variáveis que,
# apesar de numéricas, sua análise deve ser feita como categoria.
dplyr::summarise(
dplyr::across( #Identifica uma sequencia de colunas
dplyr::where(is.numeric), #Quais sao as colunas utilizadas no across
list(
mean = ~mean(., na.rm = TRUE),
median = ~median(., na.rm = TRUE),
sd = ~sd(., na.rm = TRUE),
min = ~min(., na.rm = TRUE),
max = ~max(., na.rm = TRUE),
na_percentage = ~sum(is.na(.)) / n() * 100
),
.names = "{.col}-{.fn}"  # Usando hífen como separador
)
) |>
tidyr::pivot_longer( #Transforma esses dados em uma tabela por colunas
cols = everything(),
names_to = c("Variable", ".value"),
names_sep = "-"  # Alinhando o separador com o usado acima
)
# Exibindo as estatísticas descritivas
stats
# Lendo o dataset
customer_satisfaction_df <- read.csv("data/customer_satisfaction.csv")
# Lendo o dataset
customer_satisfaction_df <- read.csv("customer_satisfaction.csv")
# Lendo o dataset
customer_satisfaction_df <- read.csv("customer_satisfaction.csv")
# Lendo o dataset
customer_satisfaction_df <- read.csv("customer_satisfaction.csv")
library(readr)
customer_satisfaction <- read_csv("Desktop/Isabella/CIENCIA_DE_DADOS_WLAD/sandbox/estudos_qualidade_dados/customer_satisfaction.csv")
View(customer_satisfaction)
# Lendo o dataset
customer_satisfaction_df <- read.csv("customer_satisfaction.csv")
getwd()
setwd("/Users/isabellastersa/Desktop/Isabella/CIENCIA_DE_DADOS_WLAD/sandbox/estudos_qualidade_dados")
#########################################################
###                  DADOS TEXTUAIS                   ###
#########################################################
setwd("/Users/isabellastersa/Desktop/Isabella/CIENCIA_DE_DADOS_WLAD/sandbox/estudos_qualidade_dados")
# Lendo o dataset
customer_satisfaction_df <- read.csv("customer_satisfaction.csv")
#########################################################
###                  DADOS TEXTUAIS                   ###
#########################################################
setwd("/Users/isabellastersa/Desktop/Isabella/CIENCIA_DE_DADOS_WLAD/sandbox/estudos_qualidade_dados")
# Lendo o dataset
customer_satisfaction_df <- read.csv("customer_satisfaction.csv")
# Análise de variáveis texto (coluna Feedback)
text_analysis <- customer_satisfaction_df |>
summarise(
average_length = mean(str_length(Feedback), na.rm = TRUE),
max_length = max(str_length(Feedback), na.rm = TRUE),
min_length = min(str_length(Feedback), na.rm = TRUE),
na_empty_percent = sum(is.na(Feedback) | Feedback == "") / n() * 100,
unique_char_lines = sum(str_detect(Feedback, "^([a-zA-Z0-9])\\1*$"), na.rm = TRUE),
n = n()
)
# Análise de variáveis texto (coluna Feedback)
text_analysis <- customer_satisfaction_df |>
dplyr::summarise(
average_length = mean(str_length(Feedback), na.rm = TRUE),
max_length = max(str_length(Feedback), na.rm = TRUE),
min_length = min(str_length(Feedback), na.rm = TRUE),
na_empty_percent = sum(is.na(Feedback) | Feedback == "") / n() * 100,
unique_char_lines = sum(str_detect(Feedback, "^([a-zA-Z0-9])\\1*$"), na.rm = TRUE),
n = n()
)
# Exibindo resultados
text_analysis
# Análise de variáveis texto (coluna Feedback)
text_analysis <- customer_satisfaction_df |>
dplyr::summarise(
average_length = mean(str_length(Feedback), na.rm = TRUE),
max_length = max(str_length(Feedback), na.rm = TRUE),
min_length = min(str_length(Feedback), na.rm = TRUE),
na_empty_percent = sum(is.na(Feedback) | Feedback == "") / n() * 100,
unique_char_lines = sum(str_detect(Feedback, "^([a-zA-Z0-9])\\1*$"), na.rm = TRUE),
n = n()
)
# Exibindo resultados
text_analysis
library("stringr")
library("dplyr")
install.packages("stringr") # Manipulação de textos
library("stringr")
# Análise de variáveis texto (coluna Feedback)
text_analysis <- customer_satisfaction_df |>
dplyr::summarise(
average_length = mean(stringr::str_length(Feedback), na.rm = TRUE),
max_length = max(stringr::str_length(Feedback), na.rm = TRUE),
min_length = min(stringr::str_length(Feedback), na.rm = TRUE),
na_empty_percent = sum(is.na(Feedback) | Feedback == "") / n() * 100,
unique_char_lines = sum(stringr::str_detect(Feedback, "^([a-zA-Z0-9])\\1*$"), na.rm = TRUE),
n = n()
)
# Exibindo resultados
text_analysis
# Análise de variáveis texto (coluna Feedback)
text_analysis <- customer_satisfaction_df %>%
dplyr::summarise(
average_length = mean(stringr::str_length(Feedback), na.rm = TRUE),
max_length = max(stringr::str_length(Feedback), na.rm = TRUE),
min_length = min(stringr::str_length(Feedback), na.rm = TRUE),
na_empty_percent = sum(is.na(Feedback) | Feedback == "") / n() * 100,
unique_char_lines = sum(stringr::str_detect(Feedback, "^([a-zA-Z0-9])\\1*$"), na.rm = TRUE),
n = n()
)
# Exibindo resultados
text_analysis
